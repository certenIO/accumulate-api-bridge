import { log } from "@ledgerhq/logs";
export const delay = (ms) => new Promise((f) => setTimeout(f, ms));
const defaults = {
    maxRetry: 4,
    interval: 300,
    intervalMultiplicator: 1.5,
    context: "",
};
export function retry(f, options) {
    const { maxRetry, interval, intervalMultiplicator, context } = {
        ...defaults,
        ...options,
    };
    function rec(remainingTry, i) {
        const result = f();
        if (remainingTry <= 0) {
            return result;
        }
        // In case of failure, wait the interval, retry the action
        return result.catch((e) => {
            log("promise-retry", context + " failed. " + remainingTry + " retry remain. " + String(e));
            return delay(i).then(() => rec(remainingTry - 1, i * intervalMultiplicator));
        });
    }
    return rec(maxRetry, interval);
}
export const atomicQueue = (job, queueIdentifier = () => "") => {
    const queues = {};
    return (...args) => {
        const id = queueIdentifier(...args);
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-ignore  FIXME
        const queue = queues[id] || Promise.resolve();
        const p = queue.then(() => job(...args));
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-ignore  FIXME
        queues[id] = p.catch(() => undefined);
        return p;
    };
};
export function execAndWaitAtLeast(ms, cb) {
    const startTime = Date.now();
    return cb().then((r) => {
        const remaining = ms - (Date.now() - startTime);
        if (remaining <= 0)
            return r;
        return delay(remaining).then(() => r);
    });
}
/**
 * promiseAllBatched(n, items, i => f(i))
 * is essentially like
 * Promise.all(items.map(i => f(i)))
 * but with a guarantee that it will not create more than n concurrent call to f
 * where f is a function that returns a promise
 */
export async function promiseAllBatched(batch, items, fn) {
    const data = Array(items.length);
    const queue = items.map((item, index) => ({
        item,
        index,
    }));
    async function step() {
        if (queue.length === 0)
            return;
        const first = queue.shift();
        if (first) {
            const { item, index } = first;
            data[index] = await fn(item, index);
        }
        await step(); // each time an item redeem, we schedule another one
    }
    // initially, we schedule <batch> items in parallel
    await Promise.all(Array(Math.min(batch, items.length))
        .fill(() => undefined)
        .map(step));
    return data;
}
//# sourceMappingURL=promise.js.map